{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numba\n",
    "from numba import jit, prange\n",
    "import multiprocessing\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_team_value_numba(team, bye_weeks, projections, positions, starting_positions):\n",
    "    weekly_scores = np.zeros(17)\n",
    "    for week in range(17):\n",
    "        available_players = [i for i, p in enumerate(team) if bye_weeks[i] != week + 1]\n",
    "        starters = select_starters_numba(available_players, projections, positions, starting_positions)\n",
    "        weekly_scores[week] = np.sum(projections[starters]) / 17\n",
    "    \n",
    "    total_score = np.sum(weekly_scores)\n",
    "    bench_strength = np.sum(projections[team]) - np.sum(projections[starters])\n",
    "    return total_score + (bench_strength * 0.1)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def select_starters_numba(available_players, projections, positions, starting_positions):\n",
    "    starters = []\n",
    "    for pos, count in starting_positions.items():\n",
    "        if pos == 4:  # FLEX\n",
    "            flex_options = sorted([(i, projections[i]) for i in available_players if positions[i] in [1, 2, 3] and i not in starters],\n",
    "                                  key=lambda x: x[1], reverse=True)\n",
    "            starters.extend([x[0] for x in flex_options[:count]])\n",
    "        else:\n",
    "            pos_players = sorted([(i, projections[i]) for i in available_players if positions[i] == pos and i not in starters],\n",
    "                                 key=lambda x: x[1], reverse=True)\n",
    "            starters.extend([x[0] for x in pos_players[:count]])\n",
    "    return starters\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_reward_numba(team, player, round_num, adp, projections, bye_weeks, positions, starting_positions):\n",
    "    team_value_before = calculate_team_value_numba(team, bye_weeks, projections, positions, starting_positions)\n",
    "    new_team = np.append(team, player)\n",
    "    team_value_after = calculate_team_value_numba(new_team, bye_weeks, projections, positions, starting_positions)\n",
    "    value_added = team_value_after - team_value_before\n",
    "    \n",
    "    adp_bonus = max(0, (200 - adp[player]) / 10) if not np.isnan(adp[player]) else 0\n",
    "    round_penalty = max(0, round_num - 12) * 5 if positions[player] in [5, 6] else 0\n",
    "    \n",
    "    if round_num <= 3 and positions[player] in [1, 2]:\n",
    "        value_added *= 1.2\n",
    "    \n",
    "    return value_added + adp_bonus - round_penalty\n",
    "\n",
    "class FantasyFootballDraftAssistant:\n",
    "    def __init__(self):\n",
    "        self.df = None\n",
    "        self.positions = {'QB': (1, 2), 'RB': (6, 9), 'WR': (5, 9), 'TE': (1, 2), 'K': (1, 1), 'DST': (1, 1)}\n",
    "        self.starting_positions = {0: 1, 1: 2, 2: 3, 3: 1, 4: 1, 5: 1, 6: 1}  # QB, RB, WR, TE, FLEX, K, DST\n",
    "        self.flex_positions = [1, 2, 3]  # RB, WR, TE\n",
    "        self.q_table = {}\n",
    "        self.alpha = 0.1  # Learning rate\n",
    "        self.gamma = 0.9  # Discount factor\n",
    "        self.epsilon = 0.1  # Exploration rate\n",
    "        self.total_episodes = 0\n",
    "        \n",
    "    def load_data(self, file_path):\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.df['ADP'] = pd.to_numeric(self.df['ADP'], errors='coerce')\n",
    "        self.df = self.df.sort_values('ADP').reset_index(drop=True)\n",
    "        self.players = np.arange(len(self.df))\n",
    "        self.adp = self.df['ADP'].values\n",
    "        self.projections = self.df['ppr_projection'].values\n",
    "        self.bye_weeks = self.df['bye_week'].values\n",
    "        self.positions_map = {'QB': 0, 'RB': 1, 'WR': 2, 'TE': 3, 'K': 5, 'DST': 6}\n",
    "        self.positions_array = np.array([self.positions_map[pos] for pos in self.df['pos']])\n",
    "        \n",
    "    def get_state(self, team, round_num):\n",
    "        pos_counts = np.bincount(self.positions_array[team], minlength=7)\n",
    "        return tuple(pos_counts.tolist() + [round_num])\n",
    "    \n",
    "    def get_actions(self, available_players, team, round_num):\n",
    "        pos_counts = np.bincount(self.positions_array[team], minlength=7)\n",
    "        valid_positions = (pos_counts < [2, 9, 9, 2, 0, 1, 1]) & ((self.positions_array != 5) & (self.positions_array != 6) | (round_num > 12))\n",
    "        return available_players[valid_positions[available_players]]\n",
    "    \n",
    "    @jit(nopython=True)\n",
    "    def train_episode_numba(self, players, adp, projections, bye_weeks, positions, starting_positions, q_table, alpha, gamma, epsilon):\n",
    "        num_teams = 12\n",
    "        teams = [np.array([], dtype=np.int64) for _ in range(num_teams)]\n",
    "        available_players = players.copy()\n",
    "        \n",
    "        for round_num in range(1, 19):\n",
    "            for team_index in range(num_teams):\n",
    "                state = self.get_state(teams[team_index], round_num)\n",
    "                actions = self.get_actions(available_players, teams[team_index], round_num)\n",
    "                \n",
    "                if len(actions) == 0:\n",
    "                    continue\n",
    "                \n",
    "                if np.random.uniform(0, 1) < epsilon:\n",
    "                    action = np.random.choice(actions)\n",
    "                else:\n",
    "                    q_values = np.array([q_table.get((state, a), 0) for a in actions])\n",
    "                    action = actions[np.argmax(q_values)]\n",
    "                \n",
    "                reward = calculate_reward_numba(teams[team_index], action, round_num, adp, projections, bye_weeks, positions, starting_positions)\n",
    "                teams[team_index] = np.append(teams[team_index], action)\n",
    "                available_players = np.array([p for p in available_players if p != action])\n",
    "                \n",
    "                next_state = self.get_state(teams[team_index], round_num + 1)\n",
    "                next_actions = self.get_actions(available_players, teams[team_index], round_num + 1)\n",
    "                \n",
    "                if len(next_actions) > 0:\n",
    "                    max_future_q = np.max([q_table.get((next_state, a), 0) for a in next_actions])\n",
    "                else:\n",
    "                    max_future_q = 0\n",
    "                \n",
    "                current_q = q_table.get((state, action), 0)\n",
    "                new_q = (1 - alpha) * current_q + alpha * (reward + gamma * max_future_q)\n",
    "                q_table[(state, action)] = new_q\n",
    "        \n",
    "        return q_table\n",
    "    \n",
    "    def train(self, num_episodes=10000):\n",
    "        return self.train_cpu(num_episodes)\n",
    "    \n",
    "    def train_cpu(self, num_episodes):\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "        episodes_per_core = num_episodes // num_cores\n",
    "        \n",
    "        with multiprocessing.Pool(num_cores) as pool:\n",
    "            results = pool.starmap(self.train_batch, [(episodes_per_core,) for _ in range(num_cores)])\n",
    "        \n",
    "        for result in results:\n",
    "            for state_action, q_value in result.items():\n",
    "                if state_action in self.q_table:\n",
    "                    self.q_table[state_action] = (self.q_table[state_action] + q_value) / 2\n",
    "                else:\n",
    "                    self.q_table[state_action] = q_value\n",
    "        \n",
    "        self.total_episodes += num_episodes\n",
    "    \n",
    "    def train_batch(self, num_episodes):\n",
    "        local_q_table = {}\n",
    "        for _ in range(num_episodes):\n",
    "            local_q_table = self.train_episode_numba(\n",
    "                self.players, self.adp, self.projections, self.bye_weeks,\n",
    "                self.positions_array, self.starting_positions, local_q_table,\n",
    "                self.alpha, self.gamma, self.epsilon\n",
    "            )\n",
    "        return local_q_table\n",
    "    \n",
    "    def recommend_players(self, team, available_players, round_num, num_recommendations=5):\n",
    "        state = self.get_state(team, round_num)\n",
    "        actions = self.get_actions(available_players, team, round_num)\n",
    "        q_values = np.array([self.q_table.get((state, a), 0) for a in actions])\n",
    "        top_indices = q_values.argsort()[-num_recommendations:][::-1]\n",
    "        return [(self.df.iloc[actions[i]], q_values[i]) for i in top_indices]\n",
    "    \n",
    "    def simulate_draft(self, user_position, num_teams=12):\n",
    "        teams = [np.array([], dtype=np.int64) for _ in range(num_teams)]\n",
    "        available_players = self.players.copy()\n",
    "        user_picks = []\n",
    "        \n",
    "        for round_num in range(1, 19):\n",
    "            draft_order = range(num_teams) if round_num % 2 == 1 else reversed(range(num_teams))\n",
    "            for pick_in_round, team_index in enumerate(draft_order):\n",
    "                if team_index == user_position:\n",
    "                    recommendations = self.recommend_players(teams[team_index], available_players, round_num)\n",
    "                    user_picks.append(((round_num - 1) * num_teams + pick_in_round + 1, recommendations))\n",
    "                    \n",
    "                    if recommendations:\n",
    "                        selected_player = recommendations[0][0].name\n",
    "                        teams[team_index] = np.append(teams[team_index], selected_player)\n",
    "                        available_players = np.array([p for p in available_players if p != selected_player])\n",
    "                else:\n",
    "                    valid_players = self.get_actions(available_players, teams[team_index], round_num)\n",
    "                    if len(valid_players) > 0:\n",
    "                        player = valid_players[np.argmin(self.adp[valid_players])]\n",
    "                        teams[team_index] = np.append(teams[team_index], player)\n",
    "                        available_players = np.array([p for p in available_players if p != player])\n",
    "        \n",
    "        return user_picks, teams\n",
    "    \n",
    "    def save_model(self, file_path):\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump((self.q_table, self.total_episodes), f)\n",
    "        print(f\"Model saved to {file_path}\")\n",
    "    \n",
    "    def load_model(self, file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            self.q_table, self.total_episodes = pickle.load(f)\n",
    "        print(f\"Model loaded from {file_path}. Total episodes: {self.total_episodes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new training...\n",
      "Training the model...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "assistant = FantasyFootballDraftAssistant()\n",
    "assistant.load_data('data//cbs_fantasy_projection_master.csv')\n",
    "\n",
    "model_file = 'data//fantasy_football_modelv2.pkl'\n",
    "if os.path.exists(model_file):\n",
    "    assistant.load_model(model_file)\n",
    "    print(\"Continuing training from saved model...\")\n",
    "else:\n",
    "    print(\"Starting new training...\")\n",
    "\n",
    "print(\"Training the model...\")\n",
    "assistant.train(num_episodes=50000)\n",
    "assistant.save_model(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\nSimulating a draft for a user in position 3...\")\n",
    "user_picks, simulated_teams = assistant.simulate_draft(user_position=2)\n",
    "\n",
    "print(\"\\nRecommendations for your picks:\")\n",
    "for pick_number, recommendations in user_picks:\n",
    "    print(f\"\\nPick {pick_number}:\")\n",
    "    for i, (player, q_value) in enumerate(recommendations, 1):\n",
    "        print(f\"  {i}. {player['player']} ({player['pos']}) - Q-value: {q_value:.2f}, ADP: {player['ADP']:.2f}\")\n",
    "\n",
    "print(\"\\nYour team:\")\n",
    "for player in simulated_teams[2]:\n",
    "    player_data = assistant.df.iloc[player]\n",
    "    print(f\"{player_data['player']} ({player_data['pos']}) - ADP: {player_data['ADP']:.2f}, Projection: {player_data['ppr_projection']:.2f}\")\n",
    "\n",
    "print(\"\\nPosition distribution for all teams:\")\n",
    "for i, team in enumerate(simulated_teams):\n",
    "    positions = pd.Series([assistant.df.iloc[p]['pos'] for p in team]).value_counts()\n",
    "    print(f\"Team {i+1}: {positions.to_dict()}\")\n",
    "\n",
    "print(\"\\nTotal projected points for each team:\")\n",
    "for i, team in enumerate(simulated_teams):\n",
    "    total_points = sum(assistant.df.iloc[p]['ppr_projection'] for p in team)\n",
    "    print(f\"Team {i+1}: {total_points:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
